{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../train_set.csv\")\n",
    "test = pd.read_csv(\"../test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>291</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>9</td>\n",
       "      <td>may</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>5076</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>7</td>\n",
       "      <td>apr</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>104</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>14</td>\n",
       "      <td>jul</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-994</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>18</td>\n",
       "      <td>jul</td>\n",
       "      <td>174</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2974</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>21</td>\n",
       "      <td>may</td>\n",
       "      <td>187</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  age         job   marital  education default  balance housing loan  \\\n",
       "0   1   43  management   married   tertiary      no      291     yes   no   \n",
       "1   2   42  technician  divorced    primary      no     5076     yes   no   \n",
       "2   3   47      admin.   married  secondary      no      104     yes  yes   \n",
       "3   4   28  management    single  secondary      no     -994     yes  yes   \n",
       "4   5   42  technician  divorced  secondary      no     2974     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome  y  \n",
       "0   unknown    9   may       150         2     -1         0  unknown  0  \n",
       "1  cellular    7   apr        99         1    251         2    other  0  \n",
       "2  cellular   14   jul        77         2     -1         0  unknown  0  \n",
       "3  cellular   18   jul       174         2     -1         0  unknown  0  \n",
       "4   unknown   21   may       187         5     -1         0  unknown  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25317.000000</td>\n",
       "      <td>25317.000000</td>\n",
       "      <td>25317.000000</td>\n",
       "      <td>25317.000000</td>\n",
       "      <td>25317.000000</td>\n",
       "      <td>25317.000000</td>\n",
       "      <td>25317.000000</td>\n",
       "      <td>25317.000000</td>\n",
       "      <td>25317.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12659.000000</td>\n",
       "      <td>40.935379</td>\n",
       "      <td>1357.555082</td>\n",
       "      <td>15.835289</td>\n",
       "      <td>257.732393</td>\n",
       "      <td>2.772050</td>\n",
       "      <td>40.248766</td>\n",
       "      <td>0.591737</td>\n",
       "      <td>0.116957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7308.532719</td>\n",
       "      <td>10.634289</td>\n",
       "      <td>2999.822811</td>\n",
       "      <td>8.319480</td>\n",
       "      <td>256.975151</td>\n",
       "      <td>3.136097</td>\n",
       "      <td>100.213541</td>\n",
       "      <td>2.568313</td>\n",
       "      <td>0.321375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-8019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6330.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12659.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18988.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1435.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25317.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>102127.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3881.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>854.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID           age        balance           day      duration  \\\n",
       "count  25317.000000  25317.000000   25317.000000  25317.000000  25317.000000   \n",
       "mean   12659.000000     40.935379    1357.555082     15.835289    257.732393   \n",
       "std     7308.532719     10.634289    2999.822811      8.319480    256.975151   \n",
       "min        1.000000     18.000000   -8019.000000      1.000000      0.000000   \n",
       "25%     6330.000000     33.000000      73.000000      8.000000    103.000000   \n",
       "50%    12659.000000     39.000000     448.000000     16.000000    181.000000   \n",
       "75%    18988.000000     48.000000    1435.000000     21.000000    317.000000   \n",
       "max    25317.000000     95.000000  102127.000000     31.000000   3881.000000   \n",
       "\n",
       "           campaign         pdays      previous             y  \n",
       "count  25317.000000  25317.000000  25317.000000  25317.000000  \n",
       "mean       2.772050     40.248766      0.591737      0.116957  \n",
       "std        3.136097    100.213541      2.568313      0.321375  \n",
       "min        1.000000     -1.000000      0.000000      0.000000  \n",
       "25%        1.000000     -1.000000      0.000000      0.000000  \n",
       "50%        2.000000     -1.000000      0.000000      0.000000  \n",
       "75%        3.000000     -1.000000      0.000000      0.000000  \n",
       "max       55.000000    854.000000    275.000000      1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           7281\n",
       "age          7281\n",
       "job          7281\n",
       "marital      7281\n",
       "education    7281\n",
       "default      7281\n",
       "balance      7281\n",
       "housing      7281\n",
       "loan         7281\n",
       "contact      7281\n",
       "day          7281\n",
       "month        7281\n",
       "duration     7281\n",
       "campaign     7281\n",
       "pdays        7281\n",
       "previous     7281\n",
       "poutcome     7281\n",
       "y            7281\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.contact == \"unknown\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>291</td>\n",
       "      <td>9</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>5076</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>104</td>\n",
       "      <td>14</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>-994</td>\n",
       "      <td>18</td>\n",
       "      <td>174</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2974</td>\n",
       "      <td>21</td>\n",
       "      <td>187</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job  marital  education  default  housing  loan  contact  month  poutcome  \\\n",
       "0   11        2          3        1        0     1        0      9         1   \n",
       "1    8        1          2        1        0     1        2      1         2   \n",
       "2    3        2          1        1        0     0        2      3         1   \n",
       "3   11        0          1        1        0     0        2      3         1   \n",
       "4    8        1          1        1        0     1        0      9         1   \n",
       "\n",
       "   age  balance  day  duration  campaign  pdays  previous  y  \n",
       "0   43      291    9       150         2     -1         0  0  \n",
       "1   42     5076    7        99         1    251         2  0  \n",
       "2   47      104   14        77         2     -1         0  0  \n",
       "3   28     -994   18       174         2     -1         0  0  \n",
       "4   42     2974   21       187         5     -1         0  0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def virtualizationData(items):\n",
    "    '''\n",
    "    将数据转成数字\n",
    "    '''\n",
    "    item_set = set(items)\n",
    "    item_ids = {}\n",
    "    new_item = []\n",
    "    for (i, item) in enumerate(item_set):\n",
    "        item_ids[item] = i\n",
    "    for item in items:\n",
    "        new_item.append(item_ids[item])\n",
    "    return new_item\n",
    "itrain = pd.DataFrame()\n",
    "itest = pd.DataFrame()\n",
    "code_cols = [\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"poutcome\"]\n",
    "for col in code_cols:\n",
    "    itrain[col] = virtualizationData(train[col])\n",
    "    itest[col] = virtualizationData(test[col])\n",
    "ori_cols = [\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\"]\n",
    "for col in ori_cols:\n",
    "    itrain[col] = train[col]\n",
    "    itest[col] = test[col]\n",
    "itrain[\"y\"] = train[\"y\"]\n",
    "itrain.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cm = train.corr()\n",
    "sns.set(font_scale=1.5)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True,\n",
    "                 square=True,fmt=\".2f\",annot_kws={\"size\":15},yticklabels=train.columns,xticklabels=train.columns)\n",
    "                 #square=True,fmt=\".2f\",annot_kws={\"size\":15},yticklabels=train.columns,xticklabels=train.columns)\n",
    "#sns.pairplot(itrain, size=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "      <td>22356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "      <td>2961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     job  marital  education  default  housing   loan  contact  month  \\\n",
       "y                                                                       \n",
       "0  22356    22356      22356    22356    22356  22356    22356  22356   \n",
       "1   2961     2961       2961     2961     2961   2961     2961   2961   \n",
       "\n",
       "   poutcome    age  balance    day  duration  campaign  pdays  previous  \n",
       "y                                                                        \n",
       "0     22356  22356    22356  22356     22356     22356  22356     22356  \n",
       "1      2961   2961     2961   2961      2961      2961   2961      2961  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itrain.groupby(\"y\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE  # 过抽样处理库SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler  # 欠抽样处理库RandomUnderSampler\n",
    "from imblearn.ensemble import EasyEnsemble  # 简单集成方法EasyEnsemble\n",
    "#修正样本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(itrain[code_cols + ori_cols], itrain[\"y\"],\n",
    "                                                    test_size = 0.3, random_state = 0)\n",
    "all_X = itrain[code_cols + ori_cols]\n",
    "all_Y = itrain[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelResult(model, name, X_train, X_test, Y_train, Y_test):\n",
    "    \"\"\"\n",
    "    模型拟合预估\n",
    "    \"\"\"\n",
    "    model.fit(X_train, Y_train)\n",
    "    train_predict = model.predict_proba(X_train)\n",
    "    test_predict = model.predict_proba(X_test)\n",
    "    print(\"model:%s train AUC[%.4f] test AUC[%.4f] test ACC[%.4f]\" % \n",
    "          (name, \n",
    "           metrics.roc_auc_score(Y_train, train_predict[:,1]),\n",
    "           metrics.roc_auc_score(Y_test, test_predict[:,1]),\n",
    "           metrics.accuracy_score(Y_test, model.predict(X_test))\n",
    "          ))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型介绍\n",
    "## GBDT\n",
    "\n",
    "\n",
    "## RF\n",
    "随机森林指的是利用多棵树对样本进行训练并预测的一种分类器。在机器学习中，随机森林是一个包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。 Leo Breiman和Adele Cutler发展出推论出随机森林的算法。 而 \"Random Forests\" 是他们的商标。 这个术语是1995年由贝尔实验室的Tin Kam Ho所提出的随机决策森林（random decision forests）而来的。这个方法则是结合 Breimans 的 \"Bootstrap aggregating\" 想法和 Ho 的\"random subspace method\"以建造决策树的集合。算法的表现形式[3]：\n",
    "\n",
    "l    用N来表示训练用例（样本）的个数，M表示特征数目。\n",
    "\n",
    "l    输入特征数目m，用于确定决策树上一个节点的决策结果；其中m应远小于M。\n",
    "\n",
    "l    从N个训练用例（样本）中以有放回抽样的方式，取样N次，形成一个训练集（即bootstrap取样），并用未抽到的用例（样本）作预测，评估其误差。\n",
    "\n",
    "l    对于每一个节点，随机选择m个特征，决策树上每个节点的决定都是基于这些特征确定的。根据这m个特征，计算其最佳的分裂方式。\n",
    "\n",
    "l    每棵树都会完整成长而不会剪枝，这有可能在建完一棵正常树状分类器后会被采用）。\n",
    "\n",
    "关于调参，随机森林有几个比较重要的参数[4]：\n",
    "\n",
    "l  max_features：\n",
    "\n",
    "随机森林允许单个决策树使用特征的最大数量。 Python为最大特征数提供了多个可选项。 下面是其中的几个：\n",
    "\n",
    "n  Auto/None ：简单地选取所有特征，每颗树都可以利用他们。这种情况下，每颗树都没有任何的限制。\n",
    "\n",
    "n  sqrt ：此选项是每颗子树可以利用总特征数的平方根个。 例如，如果变量（特征）的总数是100，所以每颗子树只能取其中的10个。“log2”是另一种相似类型的选项。\n",
    "\n",
    "n  0.2：此选项允许每个随机森林的子树可以利用变量（特征）数的20％。如果想考察的特征x％的作用， 我们可以使用“0.X”的格式。\n",
    "\n",
    "n  max_features如何影响性能和速度？ 增加max_features一般能提高模型的性能，因为在每个节点上，我们有更多的选择可以考虑。 然而，这未必完全是对的，因为它降低了单个树的多样性，而这正是随机森林独特的优点。 但是，可以肯定，你通过增加max_features会降低算法的速度。 因此，你需要适当的平衡和选择最佳max_features。\n",
    "\n",
    "l  n_estimators：\n",
    "\n",
    "在利用最大投票数或平均值来预测之前，你想要建立子树的数量。 较多的子树可以让模型有更好的性能，但同时让你的代码变慢。 你应该选择尽可能高的值，只要你的处理器能够承受的住，因为这使你的预测更好更稳定。\n",
    "\n",
    "l  min_sample_leaf：\n",
    "\n",
    "如果您以前编写过一个决策树，你能体会到最小样本叶片大小的重要性。 叶是决策树的末端节点。 较小的叶子使模型更容易捕捉训练数据中的噪声。 一般来说，我更偏向于将最小叶子节点数目设置为大于50。在你自己的情况中，你应该尽量尝试多种叶子大小种类，以找到最优的那个。\n",
    "\n",
    "\n",
    "## LR\n",
    "logistic回归又称logistic回归分析，是一种广义的线性回归分析模型，常用于数据挖掘，疾病自动诊断，经济预测等领域。例如，探讨引发疾病的危险因素，并根据危险因素预测疾病发生的概率等。Logistic回归模型的适用条件：\n",
    "\n",
    "l  因变量为二分类的分类变量或某事件的发生率，并且是数值型变量。但是需要注意，重复计数现象指标不适用于Logistic回归。\n",
    "\n",
    "l  残差和因变量都要服从二项分布。二项分布对应的是分类变量，所以不是正态分布，进而不是用最小二乘法，而是最大似然法来解决方程估计和检验问题。\n",
    "\n",
    "l  自变量和Logistic概率是线性关系\n",
    "\n",
    "l  各观测对象间相互独立。\n",
    "\n",
    " \n",
    "\n",
    "原理：如果直接将线性回归的模型扣到Logistic回归中，会造成方程二边取值区间不同和普遍的非直线关系。因为Logistic中因变量为二分类变量，某个概率作为方程的因变量估计值取值范围为0-1，但是，方程右边取值范围是无穷大或者无穷小。所以，才引入Logistic回归。\n",
    "\n",
    "Logistic回归实质：发生概率除以没有发生概率再取对数。就是这个不太繁琐的变换改变了取值区间的矛盾和因变量自变量间的曲线关系。究其原因，是发生和未发生的概率成为了比值 ，这个比值就是一个缓冲，将取值范围扩大，再进行对数变换，整个因变量改变。不仅如此，这种变换往往使得因变量和自变量之间呈线性关系，这是根据大量实践而总结。所以，Logistic回归从根本上解决因变量要不是连续变量怎么办的问题。还有，Logistic应用广泛的原因是许多现实问题跟它的模型吻合。例如一件事情是否发生跟其他数值型自变量的关系。[5]\n",
    "logistic回归又称logistic回归分析，是一种广义的线性回归分析模型，常用于数据挖掘，疾病自动诊断，经济预测等领域。例如，探讨引发疾病的危险因素，并根据危险因素预测疾病发生的概率等。Logistic回归模型的适用条件：\n",
    "\n",
    "l  因变量为二分类的分类变量或某事件的发生率，并且是数值型变量。但是需要注意，重复计数现象指标不适用于Logistic回归。\n",
    "\n",
    "l  残差和因变量都要服从二项分布。二项分布对应的是分类变量，所以不是正态分布，进而不是用最小二乘法，而是最大似然法来解决方程估计和检验问题。\n",
    "\n",
    "l  自变量和Logistic概率是线性关系\n",
    "\n",
    "l  各观测对象间相互独立。\n",
    "l  penalty：惩罚项，str类型，可选参数为l1和l2，默认为l2。用于指定惩罚项中使用的规范。newton-cg、sag和lbfgs求解算法只支持L2规范。\n",
    "L1G规范假设的是模型的参数满足拉普拉斯分布，L2假设的模型参数满足高斯分布，所谓的范式就是加上对参数的约束，使得模型更不会过拟合(overfit)，\n",
    "但是如果要说是不是加了约束就会好，这个没有人能回答，只能说，加约束的情况下，理论上应该可以获得泛化能力更强的结果。\n",
    "\n",
    "l  c：正则化系数λ的倒数，float类型，默认为1.0。必须是正浮点型数。像SVM一样，越小的数值表示越强的正则化。\n",
    "## SVM\n",
    "SVM(Support Vector Machine)指的是支持向量机，是常见的一种判别方法。在机器学习领域，是一个有监督的学习模型，通常用来进行模式识别、分类以及回归分析。SVM的主要思想可以概括为两点[1]：\n",
    "\n",
    "l  它是针对线性可分情况进行分析，对于线性不可分的情况，通过使用非线性映射算法将低维输入空间线性不可分的样本转化为高维特征空间使其线性可分，从而使得高维特征空间采用线性算法对样本的非线性特征进行线性分析成为可能。\n",
    "\n",
    "l  它基于结构风险最小化理论之上在特征空间中构建最优超平面，使得学习器得到全局最优化，并且在整个样本空间的期望以某个概率满足一定上界。\n",
    "\n",
    "       在Sklearn中，svm具有分类和回归两种（分别是SVC、SVR），本实验处理的是分类问题，故使用SVC。\n",
    "\n",
    "       对于调参，SVM模型有两个非常重要的参数C与gamma。其中 C是惩罚系数，即对误差的宽容度。c越高，说明越不能容忍出现误差,容易过拟合。C越小，容易欠拟合。C过大或过小，泛化能力变差gamma是选择RBF函数作为kernel后，该函数自带的一个参数。隐含地决定了数据映射到新的特征空间后的分布，gamma越大，支持向量越少，gamma值越小，支持向量越多[2]。支持向量的个数影响训练与预测的速度。本实验则是简单的调整了C，C一般可以选择为：10^t , t=- 4..4就是0.0001 到10000，选择的越大，表示对错误例惩罚程度越大，可能会导致模型过拟合，代码中默认不进行调参是1.0，调参之后是0.1-100,step是0.1，调参之后，将所有的结果放入LIST中，然后，返回其中最大的评分值，其参数C和模型作为最优参数C和最优模型。\n",
    "## KNN\n",
    "   邻近算法，或者说K最近邻(kNN，k-NearestNeighbor)分类算法是数据挖掘分类技术中最简单的方法之一。所谓K最近邻，就是k个最近的邻居的意思，说的是每个样本都可以用它最接近的k个邻居来代表。kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 kNN方法在类别决策时，只与极少量的相邻样本有关。由于kNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，kNN方法较其他方法更为适合[7]。\n",
    "\n",
    "       关于调参[8]：\n",
    "\n",
    "KNeighborsClassifier方法中含有8个参数（以下前两个常用）：\n",
    "\n",
    "l  n_neighbors : int, optional (default = 5)：K的取值，默认的邻居数量是5；\n",
    "\n",
    "l  weights：确定近邻的权重，“uniform”权重一样，“distance”指权重为距离的倒数，默认情况下是权重相等。也可以自己定义函数确定权重的方式；\n",
    "\n",
    "l  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'},optional：计算最近邻的方法，可根据需要自己选择；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([4.079708  , 3.88230977, 3.96591282, 4.22340617, 4.37811127,\n",
      "       3.89016228, 4.22154446, 4.56992168, 3.90031977, 3.39647675,\n",
      "       3.3395956 , 3.31014233, 4.26095185, 3.96596942, 3.63716722,\n",
      "       3.79310679, 3.58740282, 3.68983827, 3.24412942]), 'std_fit_time': array([0.28542795, 0.38773187, 0.29226028, 0.28203301, 0.1510868 ,\n",
      "       0.09211098, 0.26319956, 0.0360257 , 0.1818952 , 0.04457788,\n",
      "       0.03425302, 0.02828785, 0.06625708, 0.4093231 , 0.16265969,\n",
      "       0.02615024, 0.05709379, 0.03446675, 0.38794779]), 'mean_score_time': array([0.05356555, 0.05116343, 0.05669961, 0.06162376, 0.06912975,\n",
      "       0.06384468, 0.07689433, 0.09101448, 0.05766506, 0.05596738,\n",
      "       0.05379577, 0.05572591, 0.05814404, 0.0534626 , 0.06453185,\n",
      "       0.05961485, 0.05449262, 0.05986052, 0.04982262]), 'std_score_time': array([0.00354647, 0.0043078 , 0.00446319, 0.01281127, 0.0271714 ,\n",
      "       0.01347556, 0.01168259, 0.0187665 , 0.00449028, 0.00405931,\n",
      "       0.0029707 , 0.0059789 , 0.00703388, 0.00239762, 0.00569219,\n",
      "       0.00625392, 0.0028362 , 0.00700871, 0.00646331]), 'param_learning_rate': masked_array(data=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09,\n",
      "                   0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18,\n",
      "                   0.19],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'learning_rate': 0.01}, {'learning_rate': 0.02}, {'learning_rate': 0.03}, {'learning_rate': 0.04}, {'learning_rate': 0.05}, {'learning_rate': 0.06}, {'learning_rate': 0.07}, {'learning_rate': 0.08}, {'learning_rate': 0.09}, {'learning_rate': 0.1}, {'learning_rate': 0.11}, {'learning_rate': 0.12}, {'learning_rate': 0.13}, {'learning_rate': 0.14}, {'learning_rate': 0.15}, {'learning_rate': 0.16}, {'learning_rate': 0.17}, {'learning_rate': 0.18}, {'learning_rate': 0.19}], 'split0_test_score': array([0.9196906 , 0.92453746, 0.92605117, 0.92667814, 0.92973338,\n",
      "       0.93155322, 0.93339008, 0.93168388, 0.93266956, 0.93286902,\n",
      "       0.93045235, 0.93078555, 0.93119838, 0.93190575, 0.93019105,\n",
      "       0.93087136, 0.92930354, 0.928716  , 0.92976353]), 'split1_test_score': array([0.90503133, 0.91007378, 0.91377919, 0.9169759 , 0.9190153 ,\n",
      "       0.91967784, 0.91951858, 0.91948379, 0.91924027, 0.92095962,\n",
      "       0.91966315, 0.92124643, 0.91968402, 0.92090705, 0.9192882 ,\n",
      "       0.91872849, 0.9174297 , 0.91903077, 0.91855532]), 'split2_test_score': array([0.91895114, 0.92472764, 0.92954474, 0.93072447, 0.93152771,\n",
      "       0.93433247, 0.93513725, 0.93584849, 0.93484116, 0.93676615,\n",
      "       0.93466644, 0.93426444, 0.93454507, 0.93381991, 0.93317361,\n",
      "       0.93475148, 0.93028227, 0.9311574 , 0.93215082]), 'split3_test_score': array([0.901975  , 0.90776389, 0.91413224, 0.91823311, 0.91899514,\n",
      "       0.92190606, 0.92145954, 0.92261227, 0.92372703, 0.92380997,\n",
      "       0.92429371, 0.92236886, 0.92189598, 0.92147426, 0.92185412,\n",
      "       0.92028509, 0.91936492, 0.91965174, 0.92204094]), 'split4_test_score': array([0.91946724, 0.92239444, 0.92616584, 0.92807208, 0.93109773,\n",
      "       0.93250784, 0.93363267, 0.9339164 , 0.93528774, 0.93563116,\n",
      "       0.93650017, 0.93508619, 0.93563349, 0.93133494, 0.93487688,\n",
      "       0.93471486, 0.93390554, 0.93213109, 0.93144347]), 'mean_test_score': array([0.91302306, 0.91789944, 0.92193464, 0.92413674, 0.92607385,\n",
      "       0.92799549, 0.92862762, 0.92870897, 0.92915315, 0.93000718,\n",
      "       0.92911516, 0.92875029, 0.92859139, 0.92788838, 0.92787677,\n",
      "       0.92787026, 0.92605719, 0.9261374 , 0.92679082]), 'std_test_score': array([0.00783649, 0.00741435, 0.00663553, 0.00550408, 0.00580185,\n",
      "       0.00599067, 0.00670019, 0.0064686 , 0.00648166, 0.00641509,\n",
      "       0.00632029, 0.00586041, 0.00657272, 0.00553319, 0.00620403,\n",
      "       0.00699018, 0.00646849, 0.00566289, 0.00546989]), 'rank_test_score': array([19, 18, 17, 16, 14,  8,  6,  5,  2,  1,  3,  4,  7,  9, 10, 11, 15,\n",
      "       13, 12], dtype=int32), 'split0_train_score': array([0.93239183, 0.94397406, 0.95120859, 0.9565331 , 0.96149227,\n",
      "       0.96653859, 0.9696288 , 0.97242376, 0.97525554, 0.97622593,\n",
      "       0.97828072, 0.98083235, 0.9833986 , 0.98469724, 0.98583359,\n",
      "       0.98645929, 0.98734216, 0.98889563, 0.98939065]), 'split1_train_score': array([0.93426497, 0.94493599, 0.95250461, 0.95855176, 0.96215668,\n",
      "       0.96601842, 0.96955932, 0.97218034, 0.97521732, 0.97619898,\n",
      "       0.97870117, 0.9810675 , 0.98239826, 0.98461547, 0.98548333,\n",
      "       0.98724587, 0.98855302, 0.98816788, 0.99011007]), 'split2_train_score': array([0.92970565, 0.94018509, 0.94962635, 0.95380029, 0.9581764 ,\n",
      "       0.96267115, 0.96753671, 0.97017046, 0.97294128, 0.97586063,\n",
      "       0.97865942, 0.97972048, 0.98106842, 0.9821417 , 0.98433852,\n",
      "       0.98435792, 0.98621481, 0.98743631, 0.98912018]), 'split3_train_score': array([0.93303538, 0.94339024, 0.95155351, 0.95716093, 0.96200802,\n",
      "       0.96635323, 0.97061905, 0.97308457, 0.97536084, 0.97835362,\n",
      "       0.98074425, 0.98232141, 0.98290938, 0.98454386, 0.98607877,\n",
      "       0.98690064, 0.98799859, 0.98940914, 0.98976423]), 'split4_train_score': array([0.93104834, 0.94118357, 0.94951975, 0.95412784, 0.95926222,\n",
      "       0.96471128, 0.96907071, 0.9710518 , 0.97446209, 0.97646934,\n",
      "       0.97944375, 0.98053107, 0.98272635, 0.98429979, 0.98443947,\n",
      "       0.98660594, 0.98815844, 0.98788316, 0.98995884]), 'mean_train_score': array([0.93208923, 0.94273379, 0.95088256, 0.95603478, 0.96061912,\n",
      "       0.96525853, 0.96928292, 0.97178218, 0.97464741, 0.9766217 ,\n",
      "       0.97916586, 0.98089456, 0.9825002 , 0.98405961, 0.98523474,\n",
      "       0.98631393, 0.9876534 , 0.98835842, 0.9896688 ]), 'std_train_score': array([0.00158022, 0.00177302, 0.0011509 , 0.00181555, 0.00160397,\n",
      "       0.0014428 , 0.00100753, 0.00103899, 0.00091092, 0.00088739,\n",
      "       0.00087458, 0.0008462 , 0.00078563, 0.0009681 , 0.00071672,\n",
      "       0.00101441, 0.00081853, 0.00070782, 0.00036505])} {'learning_rate': 0.1} 0.9300071834261029\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "def modelFit(model, X, Y, cv_folds=5, early_stopping_rounds=100):\n",
    "    \"\"\"\n",
    "    树的个数\n",
    "    \"\"\"\n",
    "    params = model.get_xgb_params()\n",
    "    xgtrain = xgb.DMatrix(X, label=Y)\n",
    "    cv_params = xgb.cv(params, xgtrain, num_boost_round=model.get_params()['n_estimators'], nfold=cv_folds,\n",
    "           metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "    #print(cv_params)\n",
    "    model.set_params(n_estimators=cv_params.shape[0])\n",
    "    print(model)\n",
    "def modelFitParams(X, Y):\n",
    "    param_test1 = {\n",
    "        #step1\n",
    "        #'max_depth':range(3,10,1),\n",
    "        #'min_child_weight':range(1,6,1), \n",
    "        #step2 0.2\n",
    "        #'gamma':[i/10.0 for i in range(0,5)],\n",
    "        #step3 0.8 0.9\n",
    "        # 'subsample':[i/10.0 for i in range(6,10)],\n",
    "        # 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "        #step4 正则化调优\n",
    "        #'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "        #step5 学习率\n",
    "        'learning_rate':[i/100.0 for i in range(1, 20)],\n",
    "    }\n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier(learning_rate =0.1,\n",
    "                                                      n_estimators=152,\n",
    "                                                      max_depth=6,\n",
    "                                                      min_child_weight=4,\n",
    "                                                      gamma=0.2,\n",
    "                                                      subsample=0.9,\n",
    "                                                      colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic',\n",
    "                                                      nthread=4,\n",
    "                                                      scale_pos_weight=1,\n",
    "                                                      reg_alpha=1e-5,\n",
    "                                                      seed=27), \n",
    "                            param_grid = param_test1,\n",
    "                            scoring='roc_auc',\n",
    "                            n_jobs=4,\n",
    "                            iid=False, \n",
    "                            cv=5)\n",
    "    gsearch1.fit(X, Y)\n",
    "    print(gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "modelFitParams(X_train, Y_train)\n",
    "xgb_model = xgb.XGBClassifier(max_depth=6,n_estimators=200, num_round = 5, learning_rate=0.1,subsample=0.7\n",
    "                             , colsample_bytree=0.7)\n",
    "#modelFit(models[\"xgb\"], X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:xgb train AUC[0.9743] test AUC[0.9290] test ACC[0.9056]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.8, gamma=0.2, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=6, min_child_weight=4, missing=None,\n",
      "       n_estimators=152, n_jobs=1, nthread=4, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=1e-05, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=27, silent=True, subsample=0.9)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "LR\n",
    "l  penalty：惩罚项，str类型，可选参数为l1和l2，默认为l2。用于指定惩罚项中使用的规范。newton-cg、sag和lbfgs求解算法只支持L2规范。\n",
    "L1G规范假设的是模型的参数满足拉普拉斯分布，L2假设的模型参数满足高斯分布，所谓的范式就是加上对参数的约束，使得模型更不会过拟合(overfit)，\n",
    "但是如果要说是不是加了约束就会好，这个没有人能回答，只能说，加约束的情况下，理论上应该可以获得泛化能力更强的结果。\n",
    "\n",
    "l  c：正则化系数λ的倒数，float类型，默认为1.0。必须是正浮点型数。像SVM一样，越小的数值表示越强的正则化。\n",
    "\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "#help(xgb.cv)\n",
    "models = {\n",
    "#    \"gbdt\" : GradientBoostingClassifier(random_state=100, learning_rate=0.15),\n",
    "    #\"gbdt2\" : GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5),\n",
    "#    #10颗树\n",
    "#    \"LR\" : LogisticRegression(C=0.1,max_iter=100),\n",
    "    \"xgb\" : xgb.XGBClassifier(learning_rate =0.1,\n",
    "                                                n_estimators=152,\n",
    "                                                max_depth=6,\n",
    "                                                min_child_weight=4,\n",
    "                                                gamma=0.2,\n",
    "                                                subsample=0.9,\n",
    "                                                colsample_bytree=0.8,\n",
    "                                                objective= 'binary:logistic',\n",
    "                                                nthread=4,\n",
    "                                                scale_pos_weight=1,\n",
    "                                                reg_alpha=1e-5,\n",
    "                                                seed=27),\n",
    "#    \"xgb10\" : xgb.XGBClassifier(max_depth=6,n_estimators=100,num_round = 10),\n",
    "#    \"RF\" : RandomForestClassifier(n_estimators=100, max_depth=13, max_features=\"sqrt\", min_samples_leaf=10),\n",
    "#    \"RF_gini\" : RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini', min_samples_leaf=5),\n",
    "#    \"RF_entropy\" : RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy', min_samples_leaf=5),\n",
    "#    \"ET_gini\" : ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='gini', min_samples_leaf=5),\n",
    "#    \"ET_entropy\" : ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='entropy', min_samples_leaf=5),\n",
    "#    \"RF2\" : RandomForestClassifier(n_estimators=100),\n",
    "#    \"LR\" : LogisticRegression(C=1.0, penalty=\"l2\"),\n",
    "#    #\"LR-lbfgs\" : LogisticRegression(C=1.0, penalty=\"lbfgs\"),\n",
    "#    \"KNN\" : KNeighborsClassifier(n_neighbors=40)\n",
    "    #, \"SVM\" : SVC(C=10, probability=True)\n",
    "    \n",
    "}\n",
    "\n",
    "#print(xgb.XGBClassifier(max_depth=6,n_estimators=100,num_round = 5))\n",
    "#clf = modelResult(models[\"gbdt\"], \"gbdt\", X_train, X_test, Y_train, Y_test)\n",
    "fit_model = {}\n",
    "for name in models:\n",
    "    fit_model[name] = modelResult(models[name], name, X_train, X_test,\n",
    "                                  Y_train, Y_test)\n",
    "    #fit_model[name] = modelResult(models[name], name, all_X, X_test,\n",
    "    #                              all_Y, Y_test)\n",
    "    print(models[name])\n",
    "#    fit_model[name] = modelResult(models[name], name, X_train.append(X_train, ignore_index=True), X_test,\n",
    "#                                  Y_train.append(Y_train, ignore_index=True), Y_test)\n",
    "#print(X_train+X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveAns(model, X, name=\"ans.csv\"):\n",
    "    real = model.predict_proba(X)\n",
    "    ans = pd.DataFrame()\n",
    "    ans[\"ID\"] = test.ID\n",
    "    ans[\"pred\"] = pd.DataFrame(real[:,1])\n",
    "    ans.head()\n",
    "    ans.to_csv(\"../\" + name, index=False)\n",
    "saveAns(clf, itest[code_cols + ori_cols], name=\"xgb_adjust_param_by_cv_and_grid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test AUC:0.9669\n",
      "train AUC:0.9692\n",
      "test Accuracy:0.9372\n"
     ]
    }
   ],
   "source": [
    "clf = fit_model[\"xgb\"]\n",
    "test_predict = clf.predict_proba(X_test)\n",
    "train_predict = clf.predict_proba(X_train)\n",
    "print(\"test AUC:%.4f\" % metrics.roc_auc_score(Y_test, test_predict[:,1]))\n",
    "print(\"train AUC:%.4f\" % metrics.roc_auc_score(Y_train, train_predict[:,1]))\n",
    "print(\"test Accuracy:%.4f\" % metrics.accuracy_score(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 组合模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17721\n",
      "17721 7 17721\n",
      "7\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15'] ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\nexpected f5, f13, f12, f9, f0, f10, f4, f2, f14, f15, f7, f6, f3, f8, f11, f1 in input data\ntraining data did not have the following fields: campaign, housing, month, age, loan, marital, day, pdays, balance, education, previous, job, contact, duration, default, poutcome",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f7db27fb166c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0msplit_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mreal_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFolds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode_cols\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mori_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-f7db27fb166c>\u001b[0m in \u001b[0;36mKFolds\u001b[0;34m(n_folds, X, Y, X_predict, Y_predict, real_X)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0my_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mdataset_blend_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mdataset_blend_test_j\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mdataset_blend_real_j\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, data, ntree_limit)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mtest_dmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         class_probs = self.get_booster().predict(test_dmatrix,\n\u001b[0;32m--> 587\u001b[0;31m                                                  ntree_limit=ntree_limit)\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi:softprob\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1313\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15'] ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\nexpected f5, f13, f12, f9, f0, f10, f4, f2, f14, f15, f7, f6, f3, f8, f11, f1 in input data\ntraining data did not have the following fields: campaign, housing, month, age, loan, marital, day, pdays, balance, education, previous, job, contact, duration, default, poutcome"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#8折交\n",
    "def KFolds(n_folds, X, Y, X_predict, Y_predict, real_X):\n",
    "    print(len(Y), n_folds, len(X))\n",
    "    print(n_folds)\n",
    "    kfold = StratifiedKFold(n_splits=n_folds,random_state=0,shuffle=False)\n",
    "    #for train, test in kfold.split(X, Y):\n",
    "    #    print(np.array(X)[train])\n",
    "    #return\n",
    "    #skf = list(kfold.split(X, Y))\n",
    "    #skf = kfold.split(X, Y)\n",
    "    #skf_len = len()\n",
    "    dataset_blend_train = np.zeros((X.shape[0], n_folds))\n",
    "    dataset_blend_test = np.zeros((X_predict.shape[0], n_folds))\n",
    "    dataset_real = np.zeros((real_X.shape[0], n_folds))\n",
    "    for j, clf in enumerate(models.values()):\n",
    "        dataset_blend_test_j = np.zeros((X_test.shape[0], n_folds))\n",
    "        dataset_blend_real_j = np.zeros((real_X.shape[0], n_folds))\n",
    "        i = 0\n",
    "        for train, test in kfold.split(X, Y):\n",
    "            '''使用第i个部分作为预测，剩余的部分来训练模型，获得其预测的输出作为第i部分的新特征。'''\n",
    "            x_train, y_train, x_test, y_test = np.array(X)[train], np.array(Y)[train], np.array(X)[test], np.array(Y)[test]\n",
    "            clf.fit(x_train, y_train)\n",
    "            y_submission = clf.predict_proba(x_test)[:, 1]\n",
    "            dataset_blend_train[test, j] = y_submission\n",
    "            dataset_blend_test_j[:, i] = clf.predict_proba(X_predict)[:, 1]\n",
    "            dataset_blend_real_j[:, i] = clf.predict_proba(real_X)[:, 1]\n",
    "            i+=1\n",
    "        '''对于测试集，直接用这k个模型的预测值均值作为新的特征。'''\n",
    "        dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "        dataset_real[:, j] = dataset_blend_real_j.mean(1)\n",
    "    clf = models[\"gbdt\"]\n",
    "    clf.fit(dataset_blend_train, Y)\n",
    "    y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "    real_y = clf.predict_proba(dataset_real)[:, 1]\n",
    "    print(\"model:%s test AUC[%.4f]\" % \n",
    "      (\"blending\", \n",
    "       metrics.roc_auc_score(Y_predict, y_submission)\n",
    "      ))\n",
    "    return real_y\n",
    "split_len = int(len(X_train)/len(models))*len(models)\n",
    "split_len = len(X_train)\n",
    "print(split_len)\n",
    "real_test = KFolds(len(models), X_train[:split_len], Y_train[:split_len], X_test, Y_test, itest[code_cols + ori_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = clf.predict_proba(itest[code_cols + ori_cols])\n",
    "ans = pd.DataFrame()\n",
    "ans[\"ID\"] = test.ID\n",
    "ans[\"pred\"] = pd.DataFrame(real[:,1])\n",
    "ans.head()\n",
    "ans.to_csv(\"../ans_blend_0103.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = clf.predict_proba(itest[code_cols + ori_cols])\n",
    "ans = pd.DataFrame()\n",
    "ans[\"ID\"] = test.ID\n",
    "ans[\"pred\"] = pd.DataFrame(real[:,1])\n",
    "ans.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.to_csv(\"../ans_XGB_0103.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
